# app_new.py
# ä¿®æ­£ç‚¹ï¼š
# - st.image ã‚’ use_container_width=True ã«å¤‰æ›´ï¼ˆèµ¤ã„æ³¨æ„ã‚’è§£æ¶ˆï¼‰
# - èƒŒæ™¯è‰²ã‚’ #D7FFB6 ã«çµ±ä¸€ï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ã«å¼·åˆ¶é©ç”¨ï¼‰
# - ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡æ™‚ã® st.rerun() ã‚’å‰Šé™¤ã—ã¦ã€é€ä¿¡å¾Œã®äºŒé‡ãƒªãƒ­ãƒ¼ãƒ‰ã‚’é˜²æ­¢

import os, re, unicodedata, datetime as dt
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

APP_TITLE = "AIæ¼¢æ–¹é¸äºº"
TOP_N = 5
PCT_GAP_THRESHOLD = 0.30      # 1ä½ã¨ã®å·®ãŒ30%æœªæº€ â†’ è¿½åŠ è³ªå•å¯¾è±¡
FOLLOWUP_PAGE_SIZE = 3        # è¿½åŠ è³ªå•ï¼šå„å€™è£œ1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šä»¶æ•°
W_MAIN = 2                    # ä¸»ç—‡çŠ¶é‡ã¿
W_SUB  = 1                    # ä»–ç—‡çŠ¶é‡ã¿
PLANS  = ["Lite", "Standard", "Premium"]

# ============== åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ==============
load_dotenv()
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ’Š", layout="wide")

CUSTOM_CSS = """
<style>
/* èƒŒæ™¯ã‚’ #D7FFB6 ã«çµ±ä¸€ï¼ˆå…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å¼·åˆ¶ï¼‰ */
html, body, .stApp { background: #D7FFB6 !important; }
[data-testid="stAppViewContainer"] { background: #D7FFB6 !important; }
[data-testid="stHeader"] { background: transparent !important; }

/* å¹…åºƒï¼ˆ1.5å€ï¼‰ */
.block-container { max-width: 1740px !important; }

:root { --card:#ffffff; --ink:#0f172a; --muted:#6b7280; --stroke:#e5e7eb; }
.small { color: var(--muted); font-size: 12px; }

section.card {
  background:var(--card); border:1px solid var(--stroke); border-radius:16px;
  padding:18px 20px; margin: 12px auto; box-shadow: 0 2px 10px rgba(0,0,0,0.04);
}
.kv { margin:10px 0 2px; font-weight:600; color:#111827; }
.kv + div { margin-bottom:10px; color:#111827; white-space:pre-wrap; }
hr { border:none; border-top:1px solid var(--stroke); margin:16px 0; }
.stButton > button[kind="primary"] { background:#ef4444; border-color:#ef4444; color:#fff; }
.stButton > button[kind="primary"]:hover { background:#dc2626; border-color:#dc2626; }
.cand > button { width:100%; text-align:left; border:1px solid var(--stroke)!important; border-radius:12px!important; padding:10px 14px!important; background:#fff!important; }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# ============== CSV èª­ã¿è¾¼ã¿ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============
@st.cache_data
def load_any_csv(path: str) -> pd.DataFrame:
    if not os.path.exists(path): return pd.DataFrame()
    for enc in (None, "utf-8-sig", "cp932"):
        try:
            return pd.read_csv(path, encoding=enc) if enc else pd.read_csv(path)
        except Exception:
            pass
    return pd.read_csv(path, encoding="utf-8")

@st.cache_data
def load_data():
    sym  = load_any_csv("data/symptom_map.csv")
    main = load_any_csv("data/main_map.csv")
    km   = load_any_csv("data/kampo_master.csv")
    pm   = load_any_csv("data/product_master.csv")
    for df in (sym, main, km, pm):
        if df.empty: continue
        for c in df.columns:
            if df[c].dtype == object: df[c] = df[c].astype(str).str.strip()
    return sym, main, km, pm

symptom_map_raw, main_map_raw, kampo_master, product_master = load_data()

# ============== æ­£è¦åŒ–ï¼†åˆ†å‰²ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============
def kana_to_hira(s: str) -> str:
    return "".join(chr(ord(ch)-0x60) if 0x30A1<=ord(ch)<=0x30F6 else ch for ch in s)

def normalize_ja(s: str) -> str:
    if not isinstance(s, str): return ""
    s = unicodedata.normalize("NFKC", s)
    s = kana_to_hira(s.lower()).replace("ãƒ¼","").replace("ãƒ»"," ")
    s = re.sub(r"\s+", "", s)
    return s

SYNONYMS = {
    "ã¯ãã‘": {"åãæ°—","ã¯ãã‘","å˜”æ°—","ã‚€ã‹ã‚€ã‹"},
    "ãŠã†ã¨": {"å˜”å","åã","åã„ãŸ"},
    "ã®ã©ã®ã‹ã‚ã": {"å£æ¸‡","ã®ã©ãŒæ¸‡ã","å–‰ã®æ¸‡ã"},
    "ãšã¤ã†": {"é ­ç—›","é ­ãŒç—›ã„"},
    "ã ã‚‹ã•": {"ã ã‚‹ã„","å€¦æ€ æ„Ÿ"},
}
def unify_synonym(token: str) -> str:
    n = normalize_ja(token)
    for canon, group in SYNONYMS.items():
        if n in {normalize_ja(x) for x in group}:
            return canon
    return n

def split_multi(text: str):
    """ åŠè§’/å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ãƒ»æ”¹è¡Œãƒ»ã€Œã€ã€ã€Œï¼Œã€ã€Œ,ã€ã€Œ/ã€ã€Œï¼ã€ã‚’åŒºåˆ‡ã‚Š """
    if not isinstance(text, str): return []
    parts = re.split(r"[,\sã€ï¼Œ/ï¼]+", text)
    return [p.strip() for p in parts if p.strip()]

def split_symptoms_cell(cell: str):
    if not isinstance(cell, str): return []
    t = cell.replace("ã€", ",").replace("ï¼Œ", ",").replace("ãƒ»", ",").replace("ï¼", ",").replace("/", ",")
    parts = [p.strip() for p in t.split(",") if p.strip()]
    if len(parts) == 1 and " " in parts[0]:
        parts = [p.strip() for p in parts[0].split() if p.strip()]
    return parts

def build_sets_both(df: pd.DataFrame, text_col_candidates=("ç—‡çŠ¶","ä¸»ç—‡çŠ¶","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")):
    norm_dict, raw_dict = {}, {}
    if df.empty: return norm_dict, raw_dict
    name_col = "ç•¥ç§°" if "ç•¥ç§°" in df.columns else df.columns[0]
    text_col = None
    for c in text_col_candidates:
        if c in df.columns: text_col = c; break
    if text_col is None:
        text_col = df.columns[1] if len(df.columns)>1 else name_col
    for _, row in df.iterrows():
        name = str(row[name_col]).strip()
        items_raw  = split_symptoms_cell(str(row[text_col]).strip())
        items_norm = {unify_synonym(x) for x in items_raw if x}
        norm_dict[name] = norm_dict.get(name,set()) | items_norm
        cur = raw_dict.get(name, [])
        seen = set(cur)
        for x in items_raw:
            if x not in seen:
                cur.append(x); seen.add(x)
        raw_dict[name] = cur
    return norm_dict, raw_dict

symptom_norm_sets, symptom_raw_lists = build_sets_both(symptom_map_raw, ("ç—‡çŠ¶","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰","ä¸»ç—‡çŠ¶"))
main_norm_sets, _                   = build_sets_both(main_map_raw, ("ä¸»ç—‡çŠ¶","ç—‡çŠ¶","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"))

# ============== ãƒãƒƒãƒãƒ³ã‚° & è¿½åŠ è³ªå• ==============
def score_candidates(main_text: str, sub_text: str):
    toks_main = [unify_synonym(x) for x in split_multi(main_text)]
    toks_sub  = [unify_synonym(x) for x in split_multi(sub_text)]
    main_hits = set()
    if toks_main and main_norm_sets:
        for name, s in main_norm_sets.items():
            if any(t in s for t in toks_main): main_hits.add(name)
    pool_names = list(main_hits if main_hits else symptom_norm_sets.keys())
    rows=[]
    for name in pool_names:
        s_all_norm  = symptom_norm_sets.get(name, set())
        s_main_norm = main_norm_sets.get(name, set())
        base_hits   = sum(1 for kw in toks_sub  if kw in s_all_norm)
        main_hits2  = sum(1 for kw in toks_main if kw in s_main_norm)
        score       = W_SUB*base_hits + W_MAIN*main_hits2
        if score>0: rows.append({"ç•¥ç§°":name,"score":score,"base":base_hits,"main":main_hits2})
    if not rows: return []
    df = pd.DataFrame(rows).sort_values(["score","main","base"], ascending=[False,False,False]).head(TOP_N)
    return df.to_dict("records")

def pct_gap_large_enough(cands, threshold=PCT_GAP_THRESHOLD):
    if len(cands)<2: return True
    s1,s2=cands[0]["score"], cands[1]["score"]
    if s1<=0: return True
    return (1.0 - s2/s1) >= threshold

def all_entered_tokens_norm() -> set[str]:
    toks = [*split_multi(st.session_state.get("main_text","")), *split_multi(st.session_state.get("sub_text",""))]
    return {unify_synonym(x) for x in toks if x}

def unique_per_candidate_within_group_raw(group_names):
    entered_norm = all_entered_tokens_norm()
    group_norm = {n: symptom_norm_sets.get(n,set()) for n in group_names}
    group_raw  = {n: symptom_raw_lists.get(n,[])  for n in group_names}
    result={}
    for n in group_names:
        others = set().union(*[group_norm[o] for o in group_names if o!=n])
        uniq_norm = group_norm[n] - others
        uniq_raw  = [raw for raw in group_raw[n]
                     if (unify_synonym(raw) in uniq_norm) and (unify_synonym(raw) not in entered_norm)]
        uniq_raw_sorted = sorted(uniq_raw, key=len)
        cleaned=[]
        for x in uniq_raw_sorted:
            if not any(x in y and x!=y for y in uniq_raw_sorted):
                cleaned.append(x)
        result[n]=cleaned
    return result

def target_group(cands):
    if not cands: return []
    s1 = cands[0]["score"]
    names=[cands[0]["ç•¥ç§°"]]
    for c in cands[1:]:
        if s1>0 and (c["score"]/s1) > (1.0 - PCT_GAP_THRESHOLD):
            names.append(c["ç•¥ç§°"])
    return names

def page_slice_dict(dict_lists, page, size):
    out={}; more=False
    for name, items in dict_lists.items():
        start=page*size; end=start+size
        out[name]=items[start:end]
        if len(items)>end: more=True
    return out, more

def pretty_text_common(v):
    if v is None or (isinstance(v,float) and pd.isna(v)): return "ç‰¹ã«ãªã—"
    s=str(v)
    s=re.sub(r"(?:<br\s*/?>|\[\[BR\]\]|\\n|â|ï¼œæ”¹è¡Œï¼|<æ”¹è¡Œ>)","\n",s,flags=re.IGNORECASE)
    s=re.sub(r"ã€‚[ \t\u3000]*","ã€‚\n",s)
    s=re.sub(r"[ \t\u3000]{2,}"," ",s)
    return s.strip() if s.strip() else "ç‰¹ã«ãªã—"

def pretty_text_product(v, field_name: str):
    s=str(v)
    s=re.sub(r"(?:<br\s*/?>|\[\[BR\]\]|\\n|â|ï¼œæ”¹è¡Œï¼|<æ”¹è¡Œ>)","\n",s,flags=re.IGNORECASE)
    if field_name == "çµ„æˆ":
        for kw in [r"æ—¥å±€", r"ã‚ˆã‚Šè£½ã—ãŸ", r"ä¸Šè¨˜", r"ä»¥ä¸Šã®", r"æœ¬å‰¤7\.5gä¸­ã€\s*ä¸Šè¨˜ã®"]:
            s = re.sub(rf"[ \t\u3000]*(?={kw})", "\n", s)
        s = re.sub(r"(?<=g)[ \t\u3000]*", "\n", s)
        s = re.sub(r"ã€‚\s*", "ã€‚\n", s)
    else:
        s = re.sub(r"ã€‚[ \t\u3000]*","ã€‚\n",s)
    s=re.sub(r"[ \t\u3000]{2,}"," ",s)
    return s.strip()

def render_kampo_detail(kampo_name: str):
    st.markdown(f"## {kampo_name}")
    km = kampo_master[kampo_master["ç•¥ç§°"].astype(str)==kampo_name] if "ç•¥ç§°" in kampo_master.columns else pd.DataFrame()
    with st.container():
        st.markdown("### æ¼¢æ–¹è§£èª¬")
        if km.empty:
            st.info("æ¼¢æ–¹è–¬ãƒã‚¹ã‚¿ã«è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            preferred = ["ãµã‚ŠãŒãª","å‡ºå…¸","è¨¼","å…­ç—…ä½","è„ˆ","èˆŒ","è…¹","æ¼¢æ–¹å¼è¨¼","ä¸­åŒ»å¼è¨¼"]
            hide_cols = {"ç•¥ç§°","ç—‡çŠ¶","æ¼¢æ–¹è–¬ã®äº‹å…¸ã®ä¸¦ã³æ–¹"}
            cols = [c for c in preferred if c in km.columns] + [c for c in km.columns if c not in preferred and c not in hide_cols]
            row = km.iloc[0]
            for c in cols:
                st.markdown(f"<div class='kv'>{c}</div>", unsafe_allow_html=True)
                st.markdown(f"<div>{pretty_text_common(row[c])}</div>", unsafe_allow_html=True)

    if set(["ç•¥ç§°","å•†å“å"]).issubset(product_master.columns):
        pm = product_master[product_master["ç•¥ç§°"].astype(str)==kampo_name]
        st.markdown("### ä¿é™ºåè¼‰æ¼¢æ–¹ã‚¨ã‚­ã‚¹è£½å‰¤ä¸€è¦§")
        st.markdown("<div class='small'>è£½å‰¤åã‚’ã‚¯ãƒªãƒƒã‚¯ã§æ·»ä»˜æ–‡æ›¸æƒ…å ±ã‚’è¡¨ç¤º</div>", unsafe_allow_html=True)
        if pm.empty:
            st.info("è©²å½“è£½å“ã¯ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            for i, prod_name in enumerate(pm["å•†å“å"].dropna().astype(str).unique().tolist(), start=1):
                if st.button(f"ãƒ»{prod_name}", key=f"prod_btn_{kampo_name}_{i}", use_container_width=True):
                    st.session_state["selected_product"] = prod_name
                    st.rerun() if hasattr(st, "rerun") else st.experimental_rerun()

    if st.session_state.get("selected_product"):
        render_product_detail(kampo_name, st.session_state["selected_product"])

def render_product_detail(kampo_name: str, product_name: str):
    pm = product_master
    pm = pm[(pm["ç•¥ç§°"].astype(str)==kampo_name) & (pm["å•†å“å"].astype(str)==product_name)]
    st.markdown(f"## {product_name}ï¼ˆè£½å“è©³ç´°ï¼‰")
    if pm.empty:
        st.info("è©²å½“è£½å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); return
    row = pm.iloc[0]
    if "æ·»ä»˜æ–‡æ›¸URL" in pm.columns and str(row.get("æ·»ä»˜æ–‡æ›¸URL","")).startswith("http"):
        st.markdown(f"[æ·»ä»˜æ–‡æ›¸ã‚’é–‹ã]({row['æ·»ä»˜æ–‡æ›¸URL']})")
    display_map = {"å•†å“ç•ªå·": "ä¸€èˆ¬çš„ãªè£½å“ç•ªå·"}
    for c in pm.columns:
        if c in ["ç•¥ç§°","å•†å“å","æ·»ä»˜æ–‡æ›¸URL"]: continue
        label = display_map.get(c, c)
        st.markdown(f"<div class='kv'>{label}</div>", unsafe_allow_html=True)
        st.markdown(f"<div>{pretty_text_product(row[c], c)}</div>", unsafe_allow_html=True)

# ============== ç”»é¢æœ¬ä½“ ==============
left, center, right = st.columns([1,2,1])
with center:

    # ãƒ˜ãƒƒãƒ€ãƒ¼ç”»åƒï¼ˆã‚¿ã‚¤ãƒˆãƒ«æ–‡å­—ã¯è¡¨ç¤ºã—ãªã„ï¼‰
    header_path = "AI_Kampo_sennin_title.png"  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®
    if os.path.exists(header_path):
        st.image(header_path, use_container_width=True)
    else:
        st.markdown("## " + APP_TITLE)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆç”»åƒãŒãªã„å ´åˆã®ã¿ï¼‰

    # å³ä¸Šï¼šãƒ—ãƒ©ãƒ³ + ç„¡æ–™ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ï¼ˆ7æ—¥ï¼‰
    col_title, col_plan = st.columns([1,1])
    with col_plan:
        st.selectbox("ãƒ—ãƒ©ãƒ³", PLANS, key="plan")
        created = st.session_state.setdefault("created_at", dt.date.today())
        trial   = st.session_state.setdefault("trial_days", 7)  # 7æ—¥ã«å›ºå®š
        remain_days = (dt.date.today() - created).days
        days_left   = max(0, trial - remain_days)
        st.caption(f"ç„¡æ–™ãƒˆãƒ©ã‚¤ã‚¢ãƒ«æ®‹ã‚Šï¼š{days_left}æ—¥")

    # å…¥åŠ›ã‚«ãƒ¼ãƒ‰ï¼ˆformï¼š1å›é€ä¿¡ã§ãƒªãƒ­ãƒ¼ãƒ‰1å›ã®ã¿ã«ï¼‰
    st.markdown("<section class='card'>", unsafe_allow_html=True)
    with st.form(key="symptom_form", clear_on_submit=False):
        st.subheader("ä¸»ç—‡çŠ¶")
        st.caption("æœ€ã‚‚æ°—ã«ãªã‚‹ç—‡çŠ¶ã‚’1ã€œ2èªã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šåãæ°—ã€é ­ç—›ï¼‰")
        main_input = st.text_input("ä¸»ç—‡çŠ¶å…¥åŠ›", key="form_main",
                                   value=st.session_state.get("main_text",""),
                                   placeholder="ä¾‹ï¼šåãæ°— é ­ç—›", label_visibility="collapsed")

        st.subheader("ä»–ã«æ°—ã«ãªã‚‹ç—‡çŠ¶")
        st.caption("ä»–ã«æ°—ã«ãªã‚‹ç—‡çŠ¶ãƒ»ä½“è³ªã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã‚ã¾ã„ ã ã‚‹ã„ å£æ¸‡ ãªã©ï¼‰")
        sub_input  = st.text_area("ä»–ç—‡çŠ¶å…¥åŠ›", key="form_sub",
                                  value=st.session_state.get("sub_text",""),
                                  height=90, placeholder="ä¾‹ï¼šã‚ã¾ã„ ã ã‚‹ã„ å£æ¸‡ ãªã©", label_visibility="collapsed")

        colS, colR = st.columns([1,1])
        submitted = colS.form_submit_button("é€ä¿¡", type="primary")
        if colR.form_submit_button("ğŸ”„ æ–°ã—ã„æ¼¢æ–¹é¸ã³ã‚’å§‹ã‚ã‚‹"):
            st.session_state.update(main_text="", sub_text="", candidates=[],
                                   followup_page=0, selected_kampo=None, selected_product=None)
            # ãƒªã‚»ãƒƒãƒˆã¯ rerun ã—ã¦è‰¯ã„ï¼ˆæ“ä½œã®æ˜ç¢ºã•é‡è¦–ï¼‰
            st.rerun() if hasattr(st,"rerun") else st.experimental_rerun()
    st.markdown("</section>", unsafe_allow_html=True)

    # é€ä¿¡å‡¦ç†ï¼šãƒ•ã‚©ãƒ¼ãƒ è‡ªä½“ãŒ1å›ãƒªãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã§ã€ã“ã“ã§ã¯ rerun ã—ãªã„
    if submitted:
        st.session_state["main_text"]  = main_input
        st.session_state["sub_text"]   = sub_input
        st.session_state["candidates"] = score_candidates(main_input, sub_input)
        st.session_state["followup_page"] = 0
        st.session_state["selected_kampo"]  = None
        st.session_state["selected_product"]= None
        # â˜… rerun ã—ãªã„ï¼šäºŒé‡å®Ÿè¡Œã®åŸå› ã«ãªã‚‹ãŸã‚

    # å€™è£œè¡¨ç¤º
    cands = st.session_state.get("candidates", [])
    if cands:
        with st.container():
            st.markdown("### AIã«ã‚ˆã‚‹å‡¦æ–¹ææ¡ˆï¼ˆä¸Šä½5ä»¶ï¼‰")
            st.markdown("<div class='small'>æ¼¢æ–¹åã‚’ã‚¯ãƒªãƒƒã‚¯ã§è§£èª¬ã‚’è¡¨ç¤º</div>", unsafe_allow_html=True)
            top_score = max(c["score"] for c in cands) if cands else 1
            for i, c in enumerate(cands[:TOP_N], start=1):
                pct = int(round(95 * c["score"] / top_score)) if top_score>0 else 0
                pct = max(0, min(95, pct))
                if st.button(f"ã€{i}ä½ã€‘{c['ç•¥ç§°']}ï¼ˆç›¸æ€§ {pct}%ï¼‰", key=f"cand_{i}", use_container_width=True):
                    st.session_state["selected_kampo"]  = c["ç•¥ç§°"]
                    st.session_state["selected_product"]= None
                    # ã“ã“ã¯æŠ¼ã—ãŸç¬é–“ã«è©³ç´°ã¸ç§»ã‚‹ãŸã‚ rerun ç¶­æŒ
                    st.rerun() if hasattr(st, "rerun") else st.experimental_rerun()

        if not pct_gap_large_enough(cands, threshold=PCT_GAP_THRESHOLD):
            group = target_group(cands)
            uniq_dict_raw = unique_per_candidate_within_group_raw(group)
            page = st.session_state.get("followup_page", 0)
            sliced, more_exists = page_slice_dict(uniq_dict_raw, page, FOLLOWUP_PAGE_SIZE)

            st.markdown("**ä»–ã«ã“ã‚“ãªç—‡çŠ¶ã‚„è¦ç´ ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿï¼ˆè©²å½“ãŒã‚ã‚Œã°ãã®ä»–ã®ç—‡çŠ¶æ¬„ã«è¿½åŠ å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰**")
            shown=False
            for name in group:
                items = sliced.get(name, [])
                if items:
                    shown=True
                    st.markdown(f"- **{name}** ã«ç‰¹å¾´çš„ï¼š " + "ã€ ".join(items))
            if (not shown) and any(uniq_dict_raw.values()):
                more_exists = True
            if more_exists and st.button("ã•ã‚‰ã«ç—‡çŠ¶ã‚’ææ¡ˆã™ã‚‹"):
                st.session_state["followup_page"] = page + 1
                st.rerun() if hasattr(st, "rerun") else st.experimental_rerun()

    # æ¼¢æ–¹è©³ç´°ï¼ˆã‚¯ãƒªãƒƒã‚¯å¾Œï¼‰
    if st.session_state.get("selected_kampo"):
        render_kampo_detail(st.session_state["selected_kampo"])
