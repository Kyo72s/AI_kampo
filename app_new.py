# app_new.py
# å¤‰æ›´ç‚¹ï¼š
# - æ¼¢æ–¹è§£èª¬ã®è¡¨ç¤ºé †ã‚’æŒ‡å®šé€šã‚Šã«å¤‰æ›´ï¼ˆå‡ºå…¸â†’è¨¼â†’å…­ç—…ä½/è™šå®Ÿâ†’è„ˆâ†’èˆŒâ†’è…¹â†’æ¼¢æ–¹å¼è¨¼â†’ä¸­åŒ»å¼è¨¼â†’ä¸€èˆ¬çš„ãªè£½å“ç•ªå·ï¼‰
# - çµ„æˆã§å¿…ãšã€Œæ—¥å±€ã€ã®ç›´å‰ã§æ”¹è¡Œï¼ˆ(?<!\n)æ—¥å±€ â†’ \næ—¥å±€ï¼‰ã‚’è¿½åŠ 
# - é€ä¿¡ãƒ»ãƒªã‚»ãƒƒãƒˆãƒ»å€™è£œ/è£½å‰¤ã‚¯ãƒªãƒƒã‚¯ã®æŒ™å‹•ã¯å‰ç‰ˆã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç¶­æŒï¼ˆè–„ã•æœ€å°åŒ–ï¼‰

import os, re, unicodedata, datetime as dt
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

APP_TITLE = "AIæ¼¢æ–¹é¸äºº"
TOP_N = 5
PCT_GAP_THRESHOLD = 0.30
FOLLOWUP_PAGE_SIZE = 3
W_MAIN = 2
W_SUB  = 1
PLANS  = ["Lite", "Standard", "Premium"]

# ============== åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ==============
load_dotenv()
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ’Š", layout="wide")

CUSTOM_CSS = """
<style>
html, body, .stApp { background: #ecf7da !important; }
[data-testid="stAppViewContainer"] { background: #ecf7da !important; }
[data-testid="stHeader"] { background: transparent !important; }
.block-container { max-width: 1740px !important; }
:root { --card:#ffffff; --ink:#0f172a; --muted:#6b7280; --stroke:#e5e7eb; }
.small { color: var(--muted); font-size: 12px; }
section.card {
  background:var(--card); border:1px solid var(--stroke); border-radius:16px;
  padding:18px 20px; margin: 12px auto; box-shadow: 0 2px 10px rgba(0,0,0,0.04);
}
.kv { margin:10px 0 2px; font-weight:600; color:#111827; }
.kv + div { margin-bottom:10px; color:#111827; white-space:pre-wrap; }
hr { border:none; border-top:1px solid var(--stroke); margin:16px 0; }
.stButton > button[kind="primary"] { background:#ef4444; border-color:#ef4444; color:#fff; }
.stButton > button[kind="primary"]:hover { background:#dc2626; border-color:#dc2626; }
.cand > button { width:100%; text-align:left; border:1px solid var(--stroke)!important; border-radius:12px!important; padding:10px 14px!important; background:#fff!important; }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# ============== CSV èª­ã¿è¾¼ã¿ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============
@st.cache_data
def load_any_csv(path: str) -> pd.DataFrame:
    if not os.path.exists(path): return pd.DataFrame()
    for enc in (None, "utf-8-sig", "cp932"):
        try:
            return pd.read_csv(path, encoding=enc) if enc else pd.read_csv(path)
        except Exception:
            pass
    return pd.read_csv(path, encoding="utf-8")

@st.cache_data
def load_data():
    sym  = load_any_csv("data/symptom_map.csv")
    main = load_any_csv("data/main_map.csv")
    km   = load_any_csv("data/kampo_master.csv")
    pm   = load_any_csv("data/product_master.csv")
    for df in (sym, main, km, pm):
        if df.empty: continue
        for c in df.columns:
            if df[c].dtype == object: df[c] = df[c].astype(str).str.strip()
    return sym, main, km, pm

symptom_map_raw, main_map_raw, kampo_master, product_master = load_data()

# ============== æ­£è¦åŒ–ï¼†åˆ†å‰²ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============
def kana_to_hira(s: str) -> str:
    return "".join(chr(ord(ch)-0x60) if 0x30A1<=ord(ch)<=0x30F6 else ch for ch in s)

def normalize_ja(s: str) -> str:
    if not isinstance(s, str): return ""
    s = unicodedata.normalize("NFKC", s)
    s = kana_to_hira(s.lower()).replace("ãƒ¼","").replace("ãƒ»"," ")
    s = re.sub(r"\s+", "", s)
    return s

SYNONYMS = {
    "ã¯ãã‘": {"åãæ°—","ã¯ãã‘","å˜”æ°—","ã‚€ã‹ã‚€ã‹"},
    "ãŠã†ã¨": {"å˜”å","åã","åã„ãŸ"},
    "ã®ã©ã®ã‹ã‚ã": {"å£æ¸‡","ã®ã©ãŒæ¸‡ã","å–‰ã®æ¸‡ã"},
    "ãšã¤ã†": {"é ­ç—›","é ­ãŒç—›ã„"},
    "ã ã‚‹ã•": {"ã ã‚‹ã„","å€¦æ€ æ„Ÿ"},
}
def unify_synonym(token: str) -> str:
    n = normalize_ja(token)
    for canon, group in SYNONYMS.items():
        if n in {normalize_ja(x) for x in group}:
            return canon
    return n

def split_multi(text: str):
    if not isinstance(text, str): return []
    parts = re.split(r"[,\sã€ï¼Œ/ï¼]+", text)
    return [p.strip() for p in parts if p.strip()]

def split_symptoms_cell(cell: str):
    if not isinstance(cell, str): return []
    t = cell.replace("ã€", ",").replace("ï¼Œ", ",").replace("ãƒ»", ",").replace("ï¼", ",").replace("/", ",")
    parts = [p.strip() for p in t.split(",") if p.strip()]
    if len(parts) == 1 and " " in parts[0]:
        parts = [p.strip() for p in parts[0].split() if p.strip()]
    return parts

def build_sets_both(df: pd.DataFrame, text_col_candidates=("ç—‡çŠ¶","ä¸»ç—‡çŠ¶","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")):
    norm_dict, raw_dict = {}, {}
    if df.empty: return norm_dict, raw_dict
    name_col = "ç•¥ç§°" if "ç•¥ç§°" in df.columns else df.columns[0]
    text_col = None
    for c in text_col_candidates:
        if c in df.columns: text_col = c; break
    if text_col is None:
        text_col = df.columns[1] if len(df.columns)>1 else name_col
    for _, row in df.iterrows():
        name = str(row[name_col]).strip()
        items_raw  = split_symptoms_cell(str(row[text_col]).strip())
        items_norm = {unify_synonym(x) for x in items_raw if x}
        norm_dict[name] = norm_dict.get(name,set()) | items_norm
        cur = raw_dict.get(name, [])
        seen = set(cur)
        for x in items_raw:
            if x not in seen:
                cur.append(x); seen.add(x)
        raw_dict[name] = cur
    return norm_dict, raw_dict

symptom_norm_sets, symptom_raw_lists = build_sets_both(symptom_map_raw, ("ç—‡çŠ¶","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰","ä¸»ç—‡çŠ¶"))
main_norm_sets, _                   = build_sets_both(main_map_raw, ("ä¸»ç—‡çŠ¶","ç—‡çŠ¶","ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"))

# ============== ãƒãƒƒãƒãƒ³ã‚° & è¿½åŠ è³ªå• ==============
def score_candidates(main_text: str, sub_text: str):
    toks_main = [unify_synonym(x) for x in split_multi(main_text)]
    toks_sub  = [unify_synonym(x) for x in split_multi(sub_text)]
    main_hits = set()
    if toks_main and main_norm_sets:
        for name, s in main_norm_sets.items():
            if any(t in s for t in toks_main): main_hits.add(name)
    pool_names = list(main_hits if main_hits else symptom_norm_sets.keys())
    rows=[]
    for name in pool_names:
        s_all_norm  = symptom_norm_sets.get(name, set())
        s_main_norm = main_norm_sets.get(name, set())
        base_hits   = sum(1 for kw in toks_sub  if kw in s_all_norm)
        main_hits2  = sum(1 for kw in toks_main if kw in s_main_norm)
        score       = W_SUB*base_hits + W_MAIN*main_hits2
        if score>0: rows.append({"ç•¥ç§°":name,"score":score,"base":base_hits,"main":main_hits2})
    if not rows: return []
    df = pd.DataFrame(rows).sort_values(["score","main","base"], ascending=[False,False,False]).head(TOP_N)
    return df.to_dict("records")

def pct_gap_large_enough(cands, threshold=PCT_GAP_THRESHOLD):
    if len(cands)<2: return True
    s1,s2=cands[0]["score"], cands[1]["score"]
    if s1<=0: return True
    return (1.0 - s2/s1) >= threshold

def all_entered_tokens_norm() -> set[str]:
    toks = [*split_multi(st.session_state.get("main_text","")),
            *split_multi(st.session_state.get("sub_text",""))]
    return {unify_synonym(x) for x in toks if x}

def unique_per_candidate_within_group_raw(group_names):
    entered_norm = all_entered_tokens_norm()
    group_norm = {n: symptom_norm_sets.get(n,set()) for n in group_names}
    group_raw  = {n: symptom_raw_lists.get(n,[])  for n in group_names}
    result={}
    for n in group_names:
        others = set().union(*[group_norm[o] for o in group_names if o!=n])
        uniq_norm = group_norm[n] - others
        uniq_raw  = [raw for raw in group_raw[n]
                     if (unify_synonym(raw) in uniq_norm) and (unify_synonym(raw) not in entered_norm)]
        uniq_raw_sorted = sorted(uniq_raw, key=len)
        cleaned=[]
        for x in uniq_raw_sorted:
            if not any(x in y and x!=y for y in uniq_raw_sorted):
                cleaned.append(x)
        result[n]=cleaned
    return result

def target_group(cands):
    if not cands: return []
    s1 = cands[0]["score"]
    names=[cands[0]["ç•¥ç§°"]]
    for c in cands[1:]:
        if s1>0 and (c["score"]/s1) > (1.0 - PCT_GAP_THRESHOLD):
            names.append(c["ç•¥ç§°"])
    return names

def page_slice_dict(dict_lists, page, size):
    out={}; more=False
    for name, items in dict_lists.items():
        start=page*size; end=start+size
        out[name]=items[start:end]
        if len(items)>end: more=True
    return out, more

def pretty_text_common(v):
    if v is None or (isinstance(v,float) and pd.isna(v)): return "ç‰¹ã«ãªã—"
    s=str(v)
    s=re.sub(r"(?:<br\s*/?>|\[\[BR\]\]|\\n|â|ï¼œæ”¹è¡Œï¼|<æ”¹è¡Œ>)","\n",s,flags=re.IGNORECASE)
    s=re.sub(r"ã€‚[ \t\u3000]*","ã€‚\n",s)
    s=re.sub(r"[ \t\u3000]{2,}"," ",s)
    return s.strip() if s.strip() else "ç‰¹ã«ãªã—"

def pretty_text_product(v, field_name: str):
    s = str(v)

    # æ”¹è¡Œãƒãƒ¼ã‚«ãƒ¼ã‚’çµ±ä¸€ï¼ˆ\n ã«ï¼‰
    s = re.sub(r"(?:<br\s*/?>|\[\[BR\]\]|\\n|â|ï¼œæ”¹è¡Œï¼|<æ”¹è¡Œ>)", "\n", s, flags=re.IGNORECASE)

    if field_name == "çµ„æˆ":
        text = s

        # 1) ã€Œæœ€åˆã®ç”Ÿè–¬ã€ã®å‡ºç¾ä½ç½®ã‚’æ¢ã™ï¼ˆâ€™æ—¥å±€â€™ ã¾ãŸã¯ å’Œåï¼‹æ•°å€¤ï¼‹gï¼‰
        ing_pat = re.compile(r"(æ—¥å±€|[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³ï½¦-ï¾Ÿãƒ¼]{1,12})\s*\d+(?:\.\d+)?g")
        m = ing_pat.search(text)
        if m:
            intro, rest = text[:m.start()], text[m.start():]
        else:
            intro, rest = text, ""

        # 2) å†’é ­èª¬æ˜ï¼šå¥ç‚¹ã®ã¿ã§æ”¹è¡Œã€‚ãã®ä»–ã®æ”¹è¡Œã¯é™¤å»ã—ã¦1è¡Œã«æ•´ãˆã‚‹
        intro = intro.replace("\n", " ")
        intro = re.sub(r"ã€‚\s*", "ã€‚<br/>", intro)

        # 3) æˆåˆ†ãƒ–ãƒ­ãƒƒã‚¯
        rest = rest.replace("\n", " ")

        # 3-1) å…¨ã¦ã®ã€Œæ—¥å±€ã€ã®ç›´å‰ã«æ”¹è¡Œ
        rest = rest.replace("æ—¥å±€", "<br/>æ—¥å±€")

        # 3-2) ã€Œæ—¥å±€ãªã—ç”Ÿè–¬ã€ã§ã‚‚æ”¹è¡Œï¼ˆã‚¨ã‚­ã‚¹/ç²‰æœ«ã¯é™¤å¤–ï¼‰
        #     ç›´å‰æ•°æ–‡å­—ã«ã€Œã‚¨ã‚­ã‚¹ã€ã€Œç²‰æœ«ã€ãŒãªã„å ´åˆã®ã¿æ”¹è¡Œã‚’å…¥ã‚Œã‚‹
        #     ä¾‹:  â€¦ ã‚·ãƒ³ã‚­ã‚¯2.0g â†’ <br/>ã‚·ãƒ³ã‚­ã‚¯2.0g
        rest = re.sub(
            r"(?<!ã‚¨ã‚­ã‚¹)(?<!ç²‰æœ«)\s([ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³ï½¦-ï¾Ÿãƒ¼]{1,12})\s*([0-9]+(?:\.[0-9]+)?g)",
            r"<br/>\1\2",
            rest
        )

        # 3-3) é€£ç¶š <br/> ã‚’ 1 ã¤ã«
        rest = re.sub(r"(?:<br/>\s*){2,}", "<br/>", rest).lstrip("<br/>")

        # 4) çµåˆ
        out = (intro + rest).strip()

        # 5) ä½™åˆ†ãªç©ºç™½æ•´ç†
        out = re.sub(r"[ \t\u3000]{2,}", " ", out)

        return out

    else:
        # çµ„æˆä»¥å¤–ã¯å¾“æ¥é€šã‚Šï¼šå¥ç‚¹ã§æ”¹è¡Œ â†’ <br/> ã¸
        s = re.sub(r"ã€‚[ \t\u3000]*", "ã€‚\n", s)
        s = s.replace("\n", "<br/>")
        s = re.sub(r"[ \t\u3000]{2,}", " ", s)
        return s.strip()



def render_product_detail(kampo_name: str, product_name: str):
    pm = product_master
    pm = pm[(pm["ç•¥ç§°"].astype(str)==kampo_name) & (pm["å•†å“å"].astype(str)==product_name)]
    st.markdown(f"## {product_name}ï¼ˆè£½å“è©³ç´°ï¼‰")
    if pm.empty:
        st.info("è©²å½“è£½å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); return
    row = pm.iloc[0]
    if "æ·»ä»˜æ–‡æ›¸URL" in pm.columns and str(row.get("æ·»ä»˜æ–‡æ›¸URL","")).startswith("http"):
        st.markdown(f"[æ·»ä»˜æ–‡æ›¸ã‚’é–‹ã]({row['æ·»ä»˜æ–‡æ›¸URL']})")
    display_map = {"å•†å“ç•ªå·": "ä¸€èˆ¬çš„ãªè£½å“ç•ªå·"}
    for c in pm.columns:
        if c in ["ç•¥ç§°","å•†å“å","æ·»ä»˜æ–‡æ›¸URL"]: continue
        label = display_map.get(c, c)
        st.markdown(f"<div class='kv'>{label}</div>", unsafe_allow_html=True)
        st.markdown(f"<div>{pretty_text_product(row[c], c)}</div>", unsafe_allow_html=True)

def render_kampo_detail(kampo_name: str):
    """CSV(kampo_master.csv)ã®åˆ—åã‚’å°Šé‡ã—ãŸé †ã§æ¼¢æ–¹è§£èª¬ã‚’è¡¨ç¤ºã™ã‚‹"""
    st.markdown(f"## {kampo_name}")

    km = kampo_master[kampo_master["ç•¥ç§°"].astype(str) == kampo_name] if "ç•¥ç§°" in kampo_master.columns else pd.DataFrame()
    with st.container():
        st.markdown("### æ¼¢æ–¹è§£èª¬")
        if km.empty:
            st.info("æ¼¢æ–¹è–¬ãƒã‚¹ã‚¿ã«è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        row_dict = km.iloc[0].to_dict()

        # åˆ—åã®ç©ºç™½ã‚†ã‚‰ãã‚’å¸åï¼ˆå…¨è§’/åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã™ã¹ã¦é™¤å»ã—ã¦æ¯”è¼ƒï¼‰
        def norm_key(s: str) -> str:
            return re.sub(r"\s+", "", str(s))

        # å®Ÿåˆ—åã‚’å®‰å…¨ã«è¦‹ã¤ã‘ã‚‹
        def get_val_by_label(label: str) -> str:
            target = norm_key(label)
            for k, v in row_dict.items():
                if norm_key(k) == target:
                    return "" if v is None else str(v).strip()
            return ""

        # å€¤ã ã‘è¡¨ç¤ºï¼ˆãƒ©ãƒ™ãƒ«ç„¡ã—ï¼‰
        def show_value_only(label: str):
            v = get_val_by_label(label)
            if v:
                st.markdown(f"{pretty_text_common(v)}")

        # ãƒ©ãƒ™ãƒ«ï¼‹å€¤
        def show_labeled(label: str):
            v = get_val_by_label(label)
            if v:
                st.markdown(f"<div class='kv'>{label}</div>", unsafe_allow_html=True)
                st.markdown(f"<div>{pretty_text_common(v)}</div>", unsafe_allow_html=True)

        # 1) ç•¥ç§°ãƒ»ãµã‚ŠãŒãª ã¯ãƒ©ãƒ™ãƒ«ç„¡ã—ã§ä¸Šã«è¡¨ç¤º
        show_value_only("ç•¥ç§°")
        show_value_only("ãµã‚ŠãŒãª")

        # 2) ä»¥é™ã¯CSVã®åˆ—åã©ãŠã‚Šã€æŒ‡å®šé †ã«â€œãã®ã¾ã¾â€è¡¨ç¤º
        ordered_labels = [
            "å‡ºå…¸",
            "è¨¼ï¼ˆè¡¨è£ãƒ»å¯’ç†±ãƒ»è™šå®Ÿï¼‰",
            "å…­ç—…ä½ ï¼  è™šå®Ÿ",   # ç©ºç™½ã®æœ‰ç„¡ã¯ norm_key ã§ç„¡è¦–ã—ã¦çªãåˆã‚ã›ã¾ã™
            "è„ˆ",
            "èˆŒ",
            "è…¹",
            "æ¼¢æ–¹å¼è¨¼",
            "ä¸­åŒ»å¼è¨¼",
        ]
        for lab in ordered_labels:
            show_labeled(lab)

    # === è£½å‰¤ä¸€è¦§ï¼ˆå¾“æ¥ã©ãŠã‚Šï¼‰ ===
    if set(["ç•¥ç§°","å•†å“å"]).issubset(product_master.columns):
        pm = product_master[product_master["ç•¥ç§°"].astype(str)==kampo_name]
        st.markdown("### ä¿é™ºåè¼‰æ¼¢æ–¹ã‚¨ã‚­ã‚¹è£½å‰¤ä¸€è¦§")
        st.markdown("<div class='small'>è£½å‰¤åã‚’ã‚¯ãƒªãƒƒã‚¯ã§æ·»ä»˜æ–‡æ›¸æƒ…å ±ã‚’è¡¨ç¤º</div>", unsafe_allow_html=True)
        if pm.empty:
            st.info("è©²å½“è£½å“ã¯ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            for i, prod_name in enumerate(pm["å•†å“å"].dropna().astype(str).unique().tolist(), start=1):
                if st.button(f"ãƒ»{prod_name}", key=f"prod_btn_{kampo_name}_{i}", use_container_width=True):
                    st.session_state["selected_product"] = prod_name

    if st.session_state.get("selected_product"):
        render_product_detail(kampo_name, st.session_state["selected_product"])


# ============== ç”»é¢æœ¬ä½“ï¼ˆè–„ã•æœ€å°åŒ–ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å‰ç‰ˆã®ã¾ã¾ï¼‰ ==============
left, center, right = st.columns([1,2,1])
with center:
    # å…ˆé ­ã§ãƒªã‚»ãƒƒãƒˆå‡¦ç†ï¼ˆWidgetç”Ÿæˆå‰ã«ï¼‰
    if st.session_state.get("_do_reset"):
        for k in ["form_main","form_sub","main_text","sub_text","candidates",
                  "followup_page","selected_kampo","selected_product"]:
            st.session_state.pop(k, None)
        st.session_state["_do_reset"] = False

    header_path = "AI_Kampo_sennin_title.png"
    if os.path.exists(header_path):
        st.image(header_path, use_container_width=True)
    else:
        st.markdown("## " + APP_TITLE)

    if st.button("ğŸ”„ æ–°ã—ã„æ¼¢æ–¹é¸ã³ã‚’å§‹ã‚ã‚‹", help="å…¥åŠ›æ¬„ãƒ»å€™è£œã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™"):
        st.session_state["_do_reset"] = True
        st.rerun() if hasattr(st,"rerun") else st.experimental_rerun()

    col_title, col_plan = st.columns([1,1])
    with col_plan:
        st.selectbox("ãƒ—ãƒ©ãƒ³", PLANS, key="plan")
        created = st.session_state.setdefault("created_at", dt.date.today())
        trial   = st.session_state.setdefault("trial_days", 7)
        remain_days = (dt.date.today() - created).days
        days_left   = max(0, trial - remain_days)
        st.caption(f"ç„¡æ–™ãƒˆãƒ©ã‚¤ã‚¢ãƒ«æ®‹ã‚Šï¼š{days_left}æ—¥")

    if "form_main" not in st.session_state:
        st.session_state["form_main"] = st.session_state.get("main_text","")
    if "form_sub" not in st.session_state:
        st.session_state["form_sub"]  = st.session_state.get("sub_text","")

    st.markdown("<section class='card'>", unsafe_allow_html=True)
    with st.form("symptom_form", clear_on_submit=False):
        st.subheader("ä¸»ç—‡çŠ¶")
        st.caption("æœ€ã‚‚æ°—ã«ãªã‚‹ç—‡çŠ¶ã‚’1ã€œ2èªã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šåãæ°—ã€é ­ç—›ï¼‰")
        st.text_input("ä¸»ç—‡çŠ¶å…¥åŠ›", key="form_main",
                      placeholder="ä¾‹ï¼šåãæ°— é ­ç—›", label_visibility="collapsed")

        st.subheader("ä»–ã«æ°—ã«ãªã‚‹ç—‡çŠ¶")
        st.caption("ä»–ã«æ°—ã«ãªã‚‹ç—‡çŠ¶ãƒ»ä½“è³ªã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã‚ã¾ã„ ã ã‚‹ã„ å£æ¸‡ ãªã©ï¼‰")
        st.text_area("ä»–ç—‡çŠ¶å…¥åŠ›", key="form_sub", height=90,
                     placeholder="ä¾‹ï¼šã‚ã¾ã„ ã ã‚‹ã„ å£æ¸‡ ãªã©", label_visibility="collapsed")

        submitted = st.form_submit_button("é€ä¿¡", type="primary")
    st.markdown("</section>", unsafe_allow_html=True)

    new_cands = None
    if submitted:
        main_input = st.session_state.get("form_main","")
        sub_input  = st.session_state.get("form_sub","")
        st.session_state["main_text"]  = main_input
        st.session_state["sub_text"]   = sub_input
        new_cands = score_candidates(main_input, sub_input)
        st.session_state["candidates"] = new_cands
        st.session_state["followup_page"] = 0
        st.session_state["selected_kampo"]  = None
        st.session_state["selected_product"]= None

    cands = new_cands if new_cands is not None else st.session_state.get("candidates", [])
    if cands:
        with st.container():
            st.markdown("### AIã«ã‚ˆã‚‹å‡¦æ–¹ææ¡ˆï¼ˆä¸Šä½5ä»¶ï¼‰")
            st.markdown("<div class='small'>æ¼¢æ–¹åã‚’ã‚¯ãƒªãƒƒã‚¯ã§è§£èª¬ã‚’è¡¨ç¤º</div>", unsafe_allow_html=True)
            top_score = max(c["score"] for c in cands) if cands else 1
            for i, c in enumerate(cands[:TOP_N], start=1):
                pct = int(round(95 * c["score"] / top_score)) if top_score>0 else 0
                pct = max(0, min(95, pct))
                if st.button(f"ã€{i}ä½ã€‘{c['ç•¥ç§°']}ï¼ˆç›¸æ€§ {pct}%ï¼‰", key=f"cand_{i}", use_container_width=True):
                    st.session_state["selected_kampo"]  = c["ç•¥ç§°"]
                    st.session_state["selected_product"]= None

        if not pct_gap_large_enough(cands, threshold=PCT_GAP_THRESHOLD):
            group = target_group(cands)
            uniq_dict_raw = unique_per_candidate_within_group_raw(group)
            page = st.session_state.get("followup_page", 0)
            sliced, more_exists = page_slice_dict(uniq_dict_raw, page, FOLLOWUP_PAGE_SIZE)

            st.markdown("**ä»–ã«ã“ã‚“ãªç—‡çŠ¶ã‚„è¦ç´ ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼Ÿï¼ˆè©²å½“ãŒã‚ã‚Œã°ãã®ä»–ã®ç—‡çŠ¶æ¬„ã«è¿½åŠ å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰**")
            shown=False
            for name in group:
                items = sliced.get(name, [])
                if items:
                    shown=True
                    st.markdown(f"- **{name}** ã«ç‰¹å¾´çš„ï¼š " + "ã€ ".join(items))
            if (not shown) and any(uniq_dict_raw.values()):
                more_exists = True
            if more_exists and st.button("ã•ã‚‰ã«ç—‡çŠ¶ã‚’ææ¡ˆã™ã‚‹"):
                st.session_state["followup_page"] = page + 1

    if st.session_state.get("selected_kampo"):
        render_kampo_detail(st.session_state["selected_kampo"])









